[{"path":"index.html","id":"about-this-course","chapter":"About this Course","heading":"About this Course","text":"Effective Data Science still work--progress. chapter largely complete just needs final proof reading.like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"index.html","id":"course-description","chapter":"About this Course","heading":"Course Description","text":"Model building evaluation necessary sufficient skills effective practice data science. module develop technical personal skills required work successfully data scientist within organisation.module critically explore :effectively scope manage data science project;work openly reproducibly;efficiently acquire, manipulate, present data;interpret explain work variety stakeholders;ensure work can put production;assess ethical implications work data scientist.interdisciplinary course draw fields including statistics, computing, management science data ethics. topic investigated selection lecture videos, conference presentations academic papers, hands-lab exercises, readings industry best-practices recognised professional bodies.","code":""},{"path":"index.html","id":"schedule","chapter":"About this Course","heading":"Schedule","text":"notes intended students course MATH70076: Data Science academic year 2022/23.course scheduled take place five weeks, suggested schedule :1st week: effective data science workflows;2nd week: aquiring sharing data;3rd week: exploratory data analysis visualisation;4th week: preparing production;5th week: ethics context data science.pdf version notes may downloaded .","code":""},{"path":"index.html","id":"learning-outcomes","chapter":"About this Course","heading":"Learning outcomes","text":"successful completion module students able :Independently scope manage data science project;Source data internet web scraping APIs;Clean, explore visualise data, justifying documenting decisions made;Evaluate need (implement) approaches explainable, reproducible scalable;Appraise ethical implications data science projects, particularly risks compromising privacy fairness potential cause harm.","code":""},{"path":"index.html","id":"allocation-of-study-hours","chapter":"About this Course","heading":"Allocation of Study Hours","text":"Lectures: 10 Hours (2 hours per week)Group Teaching: 5 Hours (1 hour per week)Lab / Practical: 5 hours (1 hour per week)Independent Study: 105 hours (17 hours per week + 20 hours coursework)","code":""},{"path":"index.html","id":"assessment-structure","chapter":"About this Course","heading":"Assessment Structure","text":"course assessed entirely coursework, reflecting practical pragmatic nature course material.Coursework 1 (30%): completed fourth week course.Coursework 2 (70%): released last week course submitted following examination period Summer term.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"About this Course","heading":"Acknowledgements","text":"notes created Dr Zak Varty. inspired previous lecture series Dr Purvasha Chakravarti Imperial College London draw many resource made available R community.","code":""},{"path":"workflows-introduction.html","id":"workflows-introduction","chapter":"Introduction","heading":"Introduction","text":"Effective Data Science still work--progress. chapter readable currently undergoing final polishing.like contribute development EDS, may https://github.com/zakvarty/data_science_notes.data scientist never work alone.Within single project data scientist likely interact range people, including limited : one project managers, stakeholders subject matter experts. experts might come single specialism form multidisciplinary team, depending type work .get project put use working scale likely collaborate data engineers. also work closely data scientists, review one another’s work collaborate larger projects.Familiarity skills, processes practices make collaboration instrumental successful data scientist. aim part course provide structure organise perform work, can good collaborator current colleges future self.going require bit effort upfront, benefits compound time. get done wasting less time staring quizzically messy folders indecipherable code. also gain reputation someone good work . promotes better professional relationships greater levels trust, can turn lead working exciting impactful projects.","code":""},{"path":"workflows-organising-your-work.html","id":"workflows-organising-your-work","chapter":"2 Organising your work","heading":"2 Organising your work","text":"Effective Data Science still work--progress. chapter readable currently undergoing final polishing.like contribute development EDS, may https://github.com/zakvarty/data_science_notes.Welcome course effective data science. week ’ll considering effective data science workflows. workflows ways progressing project help produce high quality work help make good collaborator.Chapter, ’ll kick things looking can structure data\nscience projects organize work. Familiarity skills, processes\npractices collaborative working going instrumental \nbecome successful data scientist.","code":""},{"path":"workflows-organising-your-work.html","id":"what-are-we-trying-to-do","chapter":"2 Organising your work","heading":"2.1 What are we trying to do?","text":"First, let’s consider want provide data science projects sense structure organization.data scientist ’ll never work alone. Within single project ’ll interact whole range people. might project manager, one business stakeholders variety subject matter experts.experts might trained sociologists, chemists, civil servants depending exact type data science work ’re .get project put use working scale ’ll \ncollaborate data engineers. ’ll also likely work closely data scientists. smaller projects might act reviewers one another’s work. larger projects working collaboratively allow tackle larger challenges. sorts project wouldn’t feasible alone, inherent limitations time skill one individual person.Even work small organization, ’re data scientist, adopting way working ’s focused collaborating pay dividends time. inevitably return project ’re working several weeks months years future ’ll forgotten almost everything first time around. ’ll also forgotten made decisions potential options didn’t take.exactly like working current colleague shoddy poor working practices. Nobody wants colleague somebody else, let alone future self. Even working alone, treating future self current collaborator (one want get along well ) makes kind colleague pleasure work .aim week provide guiding structure organize perform work. None going particularly difficult onerous. However require bit effort front daily discipline. Like flossing, daily effort required large benefits compound time.’ll get done wasting less time staring quizzically mess \nfolders indecipherable code. ’ll also get reputation someone ’s well organized good work . promotes better professional relationships greater levels trust within team. can , turn, tead working exciting impactful projects future.","code":""},{"path":"workflows-organising-your-work.html","id":"an-r-focused-approach","chapter":"2 Organising your work","heading":"2.2 An R Focused Approach","text":"structures workflows recommend throughout rest module focused strongly workflow predominantly uses R, markdown LaTeX.Similar techniques, code software can achieve results show coding Python C, writing projects Quarto markup language. Similarly, different organizations variations best practices ’ll go together. Often organisations extensive guidance topics.important thing understand good habits build one programming language business, transferring skills new setting largely matter learning new vocabulary slightly different syntax.said, let’s get going!","code":""},{"path":"workflows-organising-your-work.html","id":"one-project-one-directory","chapter":"2 Organising your work","heading":"2.3 One Project = One Directory","text":"’s one thing take away chapter, ’s one\nGolden Rule:Every individual project work data scientist single, self-contained directory folder.worth repeating. Every single project work self-contained live single directory. analogy might separate ring-binder folder modules degree program.one golden rule deceptively simple.first issue requires predetermined scope \nisn’t going covered particular project. seems straightforward outset project often know exactly project go, link pieces work within organization.second issue second law Thermodynamics, applies equally well project management heatdeath universe. takes continual external effort prevent contents one folder becoming chaotic disordered time.said, single directory several benefits justify additional work.","code":""},{"path":"workflows-organising-your-work.html","id":"properties-of-a-well-orgainsed-project","chapter":"2 Organising your work","heading":"2.4 Properties of a Well-Orgainsed Project","text":"properties like single, well-organized project ? Ideally, ’d like organize projects following\nproperties:PortableVersion Control FriendlyReproducibleIDE friendly.Don’t worry haven’t heard terms already. ’re going look little bit detail.","code":""},{"path":"workflows-organising-your-work.html","id":"portability","chapter":"2 Organising your work","heading":"2.4.1 Portability","text":"project said portable can easily moved without breaking.might small move, like relocating directory different location computer. might also mean moderate move, say another machine dies just big deadline. Alternatively, might large shift - uses another person using different operating system.thought experiment can see ’s full spectrum portable project may may need .","code":""},{"path":"workflows-organising-your-work.html","id":"version-control-friendly","chapter":"2 Organising your work","heading":"2.4.2 Version Control Friendly","text":"project Version Control changes tracked either manually automatically. means snapshots project taken regularly gradually develops evolves time. snapshots many, incremental changes made project allow rolled back specific previous state something goes wrong.version controlled pattern working helps avoid horrendous state found - renaming final_version.doc final_final_version.doc .organising workflow around incremental changes helps acknowledge work ever finally complete. always small changes need done future.","code":""},{"path":"workflows-organising-your-work.html","id":"reproducibility","chapter":"2 Organising your work","heading":"2.4.3 Reproducibility","text":"paper, Broman et al define reproducibility project can take original data code used perform analysis using create numerical findings study.definition leads naturally several follow-questions.exactly definition? specifically mean future someone else access data code able recreate findings ? Also, reproducibility limited just numerical results? also able create associated figures, reports press releases?Another important question project needs reproduced. weeks time 10 years time? need protect project changes dependencies, like new versions packages modules? different versions R Python? Taking time scale even , different operating systems hardware?’s unlikely ’d consider someone handing floppy disk code runs Windows XP acceptably reproducible. Sure, probably find way get work, awful lot effort end.’s perhaps bit extreme example, emphasizes importance clearly defining level reproducibility ’re aiming within every project work . example also highlights amount work can required reproduce analysis, especially quite time. important explicitly think dividing effort original developer person trying reproduce analysis future.","code":""},{"path":"workflows-organising-your-work.html","id":"ide-friendly","chapter":"2 Organising your work","heading":"2.4.4 IDE Friendly","text":"final desirable property ’d like projects play nicely\nintegrated development environments.’re coding document writing data science projects ’d possible work entirely either plain text editor typing code directly command line. approaches data science workflow benefit simplicity, also expect great deal data scientist.workflows expect type everything perfectly accurately every time, recall names argument orders every function use, constantly aware current state objects within working environment.Integrated Development Environments (IDEs) applications help reduce burden, helping make effective programmer data scientist. IDEs offer tools like code completion highlighting make code easier read write. offer tools debugging, fix things going wrong, also offer environment panes don’t hold everything head . Many IDEs also often templating facilities. let save reuse snippets code can avoid typing repetitive, boilerplate code introducing errors process.Even haven’t heard IDEs , ’ve likely already used one. common examples might RStudio R-users, PyCharm python users, Visual Studio language agnostic coding environment.Whichever use, ’d like project play nicely . lets us reap benefits keeping project portable, version controlled, reproducible someone working different set-.","code":""},{"path":"workflows-organising-your-work.html","id":"project-structure","chapter":"2 Organising your work","heading":"2.5 Project Structure","text":"’ve given pretty exhaustive argument single directory project good idea. Let’s now take look inside directory define common starting layout content projects.sort project directory template mean ’ll always know find ’re looking members team . , start ’ll reiterate ’re taking opinionated approach providing sensible starting point organizing many projects.Every project going slightly different might require slight alterations suggest . Indeed, even start suggest might adapt project structure develops grows. think ’s helpful consider tailor making changes. ’m providing one size fits design, ’s great lots projects perfect none . ’s job alter refine design individual case.One final caveat get started: companies businesses many times house style write organize code projects. ’s case, follow style guide business company uses. important thing consistent individual level across entire data science team. ’s consistency reaps benefits.Okay, imagine now ’ve assigned shiny new project created single directory house project. ’ve, quite imaginatively, called directory exciting-new-project. populate folder ?rest video, ’ll define house-style organizing root\ndirectory data science projects module.Within project directory subdirectories, can tell folders file structure forward slash following names. also files directly root directory. One called readme.md another called either makefile make.r. ’re going explore files directories turn.","code":""},{"path":"workflows-organising-your-work.html","id":"readme.md","chapter":"2 Organising your work","heading":"2.5.1 README.md","text":"Let’s begin readme file. gives brief introduction project gives information project aims . readme file describe get started using project contribute development.readme written either plain text format readme.txt markdown\nformat readme.md. benefit using markdown allows light\nformatting sections headers lists using plain text characters.\ncan see using hashes mark first second level headers using bullet points unnumbered list. Whichever format use, readme file project always stored root directory typically named uppercase letters.readme file first thing someone ’s new project reads. placing readme root directory capitalising file name increase visibility file increae chances actually happening.additional benefit keeping readme root directory project code hosting services like GitHub, GitLab BitBucket display contents readme file next contents project. services also nicely format markdown use readme file.writing readme, can useful imaginge writing new, junior team member. readme file let get started project make simple contributions reading file. might also link detailed project documentation wll help new team member toward advanced understanding complex contribution.","code":""},{"path":"workflows-organising-your-work.html","id":"inside-the-readme","chapter":"2 Organising your work","heading":"2.5.2 Inside the README","text":"let’s take quick aside see detial covered within readme file.readme include name project, self-explanatory (nothing like generic chouce exciting-new-project). readme also give project status, just couple sentences say whether project still development, version oft current release , end project life-cylce, project deprecated \nclosed.Following , also include description project. state purpose work provide, link , additional context references visitors aren’t assumed familiar .project involves code depends packages give instruction install dependencies run code. might just text also include thing sline screenshots, code snippets, gifs video whole process.Tt’s also good practice include simple examples use code within project expected results, new users can confirm everything’s working local instance. Keep examples simple minimal can new usersFor longer complicated examples aren’t necessary short introductory document can add links readme explain \ndetail elsewhere.ideally short description people can report issues project also people can get started resolving issues extend \nproject way.leads one point ’ve forgotten list . section listing authors work license ’s\ndistributed. give credit people ’ve contributed \nproject license file says people may use work. license declates may use project whether give direct\nattribution work modifications use.","code":""},{"path":"workflows-organising-your-work.html","id":"data","chapter":"2 Organising your work","heading":"2.5.3 data","text":"Moving back project structure, next data directory.data directory two subdirectories one called raw one\ncalled derived. data generate part project stored raw subdirectory. ensure project reproducible, data Raw folder never edited modified.example ’ve got two different data types: Excel spreadsheet XLS file JSON file. files exacty received project stakeholder.text file metadata.txt plain text file explaining contents interpretation raw data sets. metadata include descriptions measured variables, units recorded , date file created acquired, source obtained.raw data likely isn’t going form ’s amenable analyzing straight away. get data pleasant form work, require data manipulation cleaning. manipulation cleaning applied well documented resulting cleaned files saved within derived data directory.exciting new project, can see clean versions previous data sets ready modelling. ’s also third file folder. \ndata ’ve aquired web scraping, using script within project.","code":""},{"path":"workflows-organising-your-work.html","id":"src","chapter":"2 Organising your work","heading":"2.5.4 src","text":"src source directory contains source code project. typically functions ’ve written make analysis modelling code accessible.’ve saved function R script , project, ’ve used subdirectories organise use case. ’ve got two functions used data cleaning: first replaces NA values given value, second replaces mean non-missing values.also three helper functions: first two calculate rolling mean \ngeometric mean given vector, third function scrapes \nweb data saw derived data subdirectory.","code":""},{"path":"workflows-organising-your-work.html","id":"tests","chapter":"2 Organising your work","heading":"2.5.5 tests","text":"Moving tests directory. structure directory mirrors source directory. function file counterpart file tests.test files provide example sets inputs expected outputs \nfunction. test files used check edge cases function assure\nhaven’t broken anything fixing small bug adding new capabilities function.","code":""},{"path":"workflows-organising-your-work.html","id":"analyses","chapter":"2 Organising your work","heading":"2.5.6 analyses","text":"analyses directory contains probably think bulk \ndata science work. ’s going one subdirectory major analysis ’s performed within project within might series steps collect separate scripts.activity performed step made clear name script, order ’re going perform steps. can see scripts used 2021 annual report. First script used take raw monthly receipts produce cleaned version data set saw earlier.\nfollowed trend analysis cleaned data set.Similarly spending review data cleaning step, followed forecast modelling finally production diagnostic plots compare \nforecasts.","code":""},{"path":"workflows-organising-your-work.html","id":"outputs","chapter":"2 Organising your work","heading":"2.5.7 outputs","text":"outputs directory one subdirectory meta-analysis within project. organized output type whether data, figure, table.Depending nature project, might want use modified subdirectory structure . example, ’re several numerical experiments might want arrange outputs experiment, rather output type.","code":""},{"path":"workflows-organising-your-work.html","id":"reports","chapter":"2 Organising your work","heading":"2.5.8 reports","text":"reports directory everything comes together. written documents form final deliverables project created. final documents written LaTeX markdown, source \ncompiled documents can found within directory.including content report, example figures, ’d recommend \nmaking copies figure files within reports directory. , ’ll manually update files every time modify . Instead can use relative file paths include figures. Relative file paths specify get image, starting TeX document moving levels project directory.’re using markdown LaTeX write reports, instead use online platform like overleaf latex editor Google docs write collaboratively links reports directory using additional readme files. Make sure set read write permissions links appropriately, .using online writing systems, ’ll manually upload update plots whenever modify earlier analysis. ’s one drawbacks online tools traded ease use.exciting new project, can see annual report written markdown format, compiled HTML PDF. spendiing review written LaTeX source , don’t compiled pdf version document.","code":""},{"path":"workflows-organising-your-work.html","id":"make-file","chapter":"2 Organising your work","heading":"2.5.9 make file","text":"final element template project structure make file. aren’t going cover read write make files course. Instead, ’ll give brief description supposed .high level, make file just text file. makes special contains. Similar shell bash script, make file contains code run command line. code create update element project.make file defines shorthand commands full lines code create element project. make file also records order operations happen, steps dependent one another. means one step part project updated changes propagated entire project. done quite clever way part projects re-run need updated.’re omitting make files course ’re fiendishly difficult write read, rather require reasonable foundation working command line understood. suggest instead throughout course create R markdown file called make. file define intended running order dependencies project R file, might also automate parts analysis.","code":""},{"path":"workflows-organising-your-work.html","id":"wrapping-up","chapter":"2 Organising your work","heading":"2.6 Wrapping up","text":"Wrapping , ’s everything video.’ve introduced project structure serve well baseline vast majority projects data science.work, remember key standardisation. Working consistently across projects, company group important sticking rigidly particular structure defined .two notable exceptions probably don’t want use project structure. ’s ’re building app ’re building package. require specific organisation files within project directory. ’ll\nexplore project structure used package development live\nsession week.","code":""},{"path":"workflows-naming.html","id":"workflows-naming","chapter":"3 Naming Files","heading":"3 Naming Files","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"workflows-naming.html","id":"naming-things","chapter":"3 Naming Files","heading":"3.1 Naming things","text":"Naming things\nJenny Bryan slide summary (https://speakerdeck.com/jennybc/--name-files)\nlike file names :\nMachine Readable\nHuman Readable\nOrder friendly\n\nMachine readable:\nregex globbing friendly: avoid spaces, punctuation, accents, cases\neasy compute : deliberate use delimiters (spaces aren’t spaces)\nhyphens separate words, underscores separate metadata\n\nuseful : searching files later, narrow file list based names, extract information file names, new regex (sadist)\n\nHuman Readable:\nName contains information content. ( untitled31.R, finalreportV8.docx, temp.txt)\nconnects concept slug URLs\nset filenames want 3am deadline?\n\nDefault order friendly\nput something numeric first\nuse ISO 8601 standard dates: YYYY-MM-DD\nleft pad zeros achieve chronological logical order within directory\n\nSummary:\nMachine readable, human readable, default order friendly\nBrushing teeth analogy: tedious get habit. Huge long-term rewards\n\nJenny Bryan slide summary (https://speakerdeck.com/jennybc/--name-files)Jenny Bryan slide summary (https://speakerdeck.com/jennybc/--name-files)like file names :\nMachine Readable\nHuman Readable\nOrder friendly\nlike file names :Machine ReadableHuman ReadableOrder friendlyMachine readable:\nregex globbing friendly: avoid spaces, punctuation, accents, cases\neasy compute : deliberate use delimiters (spaces aren’t spaces)\nhyphens separate words, underscores separate metadata\n\nuseful : searching files later, narrow file list based names, extract information file names, new regex (sadist)\nMachine readable:regex globbing friendly: avoid spaces, punctuation, accents, caseseasy compute : deliberate use delimiters (spaces aren’t spaces)\nhyphens separate words, underscores separate metadata\nhyphens separate words, underscores separate metadatauseful : searching files later, narrow file list based names, extract information file names, new regex (sadist)Human Readable:\nName contains information content. ( untitled31.R, finalreportV8.docx, temp.txt)\nconnects concept slug URLs\nset filenames want 3am deadline?\nHuman Readable:Name contains information content. ( untitled31.R, finalreportV8.docx, temp.txt)connects concept slug URLsWhich set filenames want 3am deadline?Default order friendly\nput something numeric first\nuse ISO 8601 standard dates: YYYY-MM-DD\nleft pad zeros achieve chronological logical order within directory\nDefault order friendlyput something numeric firstuse ISO 8601 standard dates: YYYY-MM-DDleft pad zeros achieve chronological logical order within directorySummary:\nMachine readable, human readable, default order friendly\nBrushing teeth analogy: tedious get habit. Huge long-term rewards\nSummary:Machine readable, human readable, default order friendlyBrushing teeth analogy: tedious get habit. Huge long-term rewards","code":""},{"path":"workflows-code.html","id":"workflows-code","chapter":"4 Code","heading":"4 Code","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"workflows-code.html","id":"code","chapter":"4 Code","heading":"4.1 Code","text":"Code\nthing twice write function\nwrite function, document \nwrite function, test \nmight ever want use function , add package\nnaming things revisited:\nfunctions=verbs,\nobjects=nouns,\nreadable code,\nCamelCase snakecase pointless.points\ntidyverse google style guides R\n\nfilepaths relative root directory (top level project)\nadvanced: ::\n\nthing twice write functionIf write function, document itIf write function, test itIf might ever want use function , add packagenaming things revisited:\nfunctions=verbs,\nobjects=nouns,\nreadable code,\nCamelCase snakecase pointless.points\ntidyverse google style guides R\nfunctions=verbs,objects=nouns,readable code,CamelCase snakecase pointless.pointstidyverse google style guides Rall filepaths relative root directory (top level project)\nadvanced: ::\nadvanced: ::","code":""},{"path":"workflows-project-management.html","id":"workflows-project-management","chapter":"5 Project Management","heading":"5 Project Management","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"workflows-project-management.html","id":"bigger-picture-project-management","chapter":"5 Project Management","heading":"5.1 Bigger Picture: Project management","text":"Project management\nDefining outcomes\nscoping projects, (rememberer said code single project live single directory?)\ncontinuous development, agile + jira ?\nLinking github (extension)\nDefining outcomesscoping projects, (rememberer said code single project live single directory?)continuous development, agile + jira ?Linking github (extension)","code":""},{"path":"workflows-checklist.html","id":"workflows-checklist","chapter":"Workflows: Checklist","heading":"Workflows: Checklist","text":"Effective Data Science still work--progress. chapter undergoing heavy restructuring may confusing incomplete.like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"workflows-checklist.html","id":"videos-chapters","chapter":"Workflows: Checklist","heading":"5.2 Videos / Chapters","text":"Organising workNaming FilesOrganising codeProject Management (AY 2023/24 onward)","code":""},{"path":"workflows-checklist.html","id":"reading","chapter":"Workflows: Checklist","heading":"5.3 Reading","text":"Good enough practices scientific computingGood enough practices scientific computingBayesian workflows: Michael BetancourtBayesian workflows: Michael Betancourthttps://www.atlassian.com/agile/project-managementhttps://www.atlassian.com/agile/project-managementR4DS project workflowR4DS project workflowhere::herehere::hereR packagesR packageshappy git Rhappy git R","code":""},{"path":"workflows-checklist.html","id":"tasks","chapter":"Workflows: Checklist","heading":"5.4 Tasks","text":"go github find 3 different data science projects, explore organise work.create projects course assignments.bonus: put Github (make sure assignments private repos!)","code":""},{"path":"workflows-checklist.html","id":"live-session","chapter":"Workflows: Checklist","heading":"5.5 Live Session","text":"Discussion point live session:make assignment projects subdirectories stand alone projects? ?make assignment projects subdirectories stand alone projects? ?terms met readings?terms met readings?Activity live session:making minimal R package course","code":""},{"path":"data-introduction.html","id":"data-introduction","chapter":"Introduction","heading":"Introduction","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.Data can difficult acquire gnarly get .","code":""},{"path":"data-tabular.html","id":"data-tabular","chapter":"6 Tabular Data","heading":"6 Tabular Data","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"data-tabular.html","id":"reading-tabular-data","chapter":"6 Tabular Data","heading":"6.1 Reading Tabular Data","text":"","code":""},{"path":"data-tabular.html","id":"excel-is-not-the-only-file-type","chapter":"6 Tabular Data","heading":"6.1.1 Excel is not the only file type","text":"(Img: Oranges fruit book cover)data seen already:\ntabular data: csv, tsv\nlist-like data: JSON, XML","code":""},{"path":"data-tabular.html","id":"reading-in-tabular-data","chapter":"6 Tabular Data","heading":"6.1.2 Reading in tabular data","text":"read.csv() base R function load csv file memory.Whirlwind tour reading file formats..r readr::read_csv(file = \"path//file.csv\")\n.r readr::read_tsv(file = \"path//file.tsv\")\n.r readr::read_delim(file = \"path//file.txt\", sep =\" \")csvs read using read.csv() tabular data created data.frame R.ideal several reasons:Pretty printing: print method tibbles highlighting defaults first 10 rows, columns fit screen. addition name, column reports type.limited printing designed don’t accidentally overwhelm console print large data frames. can override default printing behaviour specifying number rows n number columns width like print part function call.Type stability: subset data.frame, type object get back depends ask . can lead forgotten edge cases writing functions work create data frames.extracted row still data.frame:\nprint(example_data_frame[1,])\nclass(example_data_frame[1,])extracted column vector:\nprint(example_data_frame[,1])\nclass(example_data_frame[,1])Similar bugs can introduced data frames allowing partial matching: column names used subsetting partially matched strings quietly continue function add another column breaks partial match.Reproducibility: Base R functions inherit behaviour operating system environment variables, import code works computer might work someone else’sstringsAsFactors = FALSE","code":"set.seed(1234)\nexample_data_frame <- data.frame(\n  gaussian = rnorm(10), \n  uniform = runif(10), \n  gamma = rgamma(10,1,1))\n\nset.seed(1234)\nexample_tibble <- tibble::tibble(\n  gaussian = rnorm(10),\n  uniform = runif(10),\n  gamma = rgamma(10,1,1))example_data_frame$uniform\nexample_data_frame$u\nexample_data_frame[[\"u\"]]\n\nexample_data_frame$gaussian\nexample_data_frame$gaus\nexample_data_frame$g          # returns NULL b/c of name conflict\n\nexample_tibble$g              # returns NULL and a warning messagenycflights13::flights %>% \n  print(n = 10, width = Inf)"},{"path":"data-webscraping.html","id":"data-webscraping","chapter":"7 Web Scraping","heading":"7 Web Scraping","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"data-webscraping.html","id":"what-is-webscraping","chapter":"7 Web Scraping","heading":"7.1 What is Webscraping","text":"","code":""},{"path":"data-apis.html","id":"data-apis","chapter":"8 APIs","heading":"8 APIs","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"data-apis.html","id":"apis","chapter":"8 APIs","heading":"8.1 APIs","text":"","code":""},{"path":"data-sql.html","id":"data-sql","chapter":"9 SQL","heading":"9 SQL","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.(Content added AY 2023-24)","code":""},{"path":"data-sql.html","id":"databases-and-sql","chapter":"9 SQL","heading":"9.1 Databases and SQL","text":"Structure webpage. Web Scraping source dataStructure webpage. Web Scraping source dataAPIs source data, data files beyond csv.APIs source data, data files beyond csv.Data bases SQLData bases SQLData always nicely formatted csvData always nicely formatted csvBeginner: reading clipboard googlesheetsBeginner: reading clipboard googlesheetsIntermediate: reading messy csvs making workflow robust new versionsIntermediate: reading messy csvs making workflow robust new versionsAdvanced:\nWebscraping APIs data sources, data files beyond CSV\ndata files beyond csv, benefits drawbacks: JSON, xml, parquet, .Rdata, .pkl\nData bases data sources: Basic SQL verbs\nLearning SQL theory small scale: dplyr verbs\nAdvanced:Webscraping APIs data sources, data files beyond CSVdata files beyond csv, benefits drawbacks: JSON, xml, parquet, .Rdata, .pklData bases data sources: Basic SQL verbsLearning SQL theory small scale: dplyr verbs","code":""},{"path":"data-checklist.html","id":"data-checklist","chapter":"Checklist","heading":"Checklist","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"data-checklist.html","id":"videos-chapters-1","chapter":"Checklist","heading":"9.2 Videos / Chapters","text":"[ ][ ][ ][ ][ ][ ]","code":""},{"path":"data-checklist.html","id":"reading-1","chapter":"Checklist","heading":"9.3 Reading","text":"","code":""},{"path":"data-checklist.html","id":"activities","chapter":"Checklist","heading":"9.4 Activities","text":"","code":""},{"path":"data-checklist.html","id":"live-session-1","chapter":"Checklist","heading":"9.5 Live Session","text":"","code":""},{"path":"edav-introduction.html","id":"edav-introduction","chapter":"Introduction","heading":"Introduction","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"edav-cleaning.html","id":"edav-cleaning","chapter":"11 Data Cleaning","heading":"11 Data Cleaning","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"edav-analysis.html","id":"edav-analysis","chapter":"12 Exploratory Data Analysis","heading":"12 Exploratory Data Analysis","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"edav-visualisation.html","id":"edav-visualisation","chapter":"13 Data Visualisation","heading":"13 Data Visualisation","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"edav-checklist.html","id":"edav-checklist","chapter":"Checklist","heading":"Checklist","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"edav-checklist.html","id":"videos-chapters-2","chapter":"Checklist","heading":"13.1 Videos / Chapters","text":"[ ][ ][ ][ ][ ][ ]","code":""},{"path":"edav-checklist.html","id":"reading-2","chapter":"Checklist","heading":"13.2 Reading","text":"","code":""},{"path":"edav-checklist.html","id":"activities-1","chapter":"Checklist","heading":"13.3 Activities","text":"","code":""},{"path":"edav-checklist.html","id":"live-session-2","chapter":"Checklist","heading":"13.4 Live Session","text":"","code":""},{"path":"production-introduction.html","id":"production-introduction","chapter":"Introduction","heading":"Introduction","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"production-reproducibility.html","id":"production-reproducibility","chapter":"14 Reproducibility","heading":"14 Reproducibility","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"production-reproducibility.html","id":"reproducibility-and-replicability","chapter":"14 Reproducibility","heading":"14.1 Reproducibility and Replicability —————————–","text":"Write chapter following structure articlehttps://www.kdnuggets.com/2019/11/reproducibility-replicability-data-science.htmlhttps://www.kdnuggets.com/2019/11/reproducibility-replicability-data-science.htmlThe Ethical Algorithm M Kearns Roth (Chapter 4) https://library-search.imperial.ac.uk/discovery/fulldisplay?docid=alma991000531083101591&context=L&vid=44IMP_INST:ICL_VU1&lang=en&search_scope=MyInst_and_CI&adaptor=Local%20Search%20Engine&tab=Everything&query=,contains,kearns%20and%20roth&mode=BasicThe Ethical Algorithm M Kearns Roth (Chapter 4) https://library-search.imperial.ac.uk/discovery/fulldisplay?docid=alma991000531083101591&context=L&vid=44IMP_INST:ICL_VU1&lang=en&search_scope=MyInst_and_CI&adaptor=Local%20Search%20Engine&tab=Everything&query=,contains,kearns%20and%20roth&mode=BasicThe ASA Statement \\(p\\)-values: Context, Process Purpose https://library-search.imperial.ac.uk/discovery/fulldisplay?docid=cdi_informaworld_taylorfrancis_310_1080_00031305_2016_1154108&context=PC&vid=44IMP_INST:ICL_VU1&lang=en&search_scope=MyInst_and_CI&adaptor=Primo%20Central&tab=Everything&query=,contains,ASA%20p-value&offset=0The ASA Statement \\(p\\)-values: Context, Process Purpose https://library-search.imperial.ac.uk/discovery/fulldisplay?docid=cdi_informaworld_taylorfrancis_310_1080_00031305_2016_1154108&context=PC&vid=44IMP_INST:ICL_VU1&lang=en&search_scope=MyInst_and_CI&adaptor=Primo%20Central&tab=Everything&query=,contains,ASA%20p-value&offset=0The garden forking paths: multiple comparisons can problem,\neven “Fishing expedition” “p-hacking” research\nhypothesis posited ahead time. Gelman E loken (2013) http://stat.columbia.edu/~gelman/research/unpublished/forking.pdfThe garden forking paths: multiple comparisons can problem,\neven “Fishing expedition” “p-hacking” research\nhypothesis posited ahead time. Gelman E loken (2013) http://stat.columbia.edu/~gelman/research/unpublished/forking.pdfhttps://docker-curriculum.com/ Prakhar Srivastavhttps://docker-curriculum.com/ Prakhar Srivastav","code":""},{"path":"production-explainability.html","id":"production-explainability","chapter":"15 Explainability","heading":"15 Explainability","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"production-explainability.html","id":"explainability--","chapter":"15 Explainability","heading":"15.1 Explainability ————————————————-","text":"LIME paper ArXiV: https://arxiv.org/abs/1602.04938. Ribeiro et al (2016) “Trust ?”: Explaining Predictions Classifier.LIME paper ArXiV: https://arxiv.org/abs/1602.04938. Ribeiro et al (2016) “Trust ?”: Explaining Predictions Classifier.LIME pacakge documentation CRAN https://cran.r-project.org/web/packages/lime/index.htmlLIME pacakge documentation CRAN https://cran.r-project.org/web/packages/lime/index.htmlUnderstanding LIME tutorial - T Pedersen M BenestyUnderstanding LIME tutorial - T Pedersen M Benestyhttps://cran.r-project.org/web/packages/lime/vignettes/Understanding_lime.htmlReference: Interpretable Machine Learning: Guide Making Black Box Models Explainable Christoph Molnar","code":""},{"path":"production-scalability.html","id":"production-scalability","chapter":"16 Scalability","heading":"16 Scalability","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"production-scalability.html","id":"scalability","chapter":"16 Scalability","heading":"16.1 Scalability ————————————————–","text":"Structure talk around Alex’s parallelisation slidesCode profilingCode profilingvectorisevectoriseparalleliseparalleliseUse better language: C++, PythonUse better language: C++, PythonDocumentation forDocumentation forapplyapplypurr::mappurr::mapfurr::pmapfurr::pmapAdvanced R (Second Edition) Hadley Wickham. Chapters 23 24, measuring improving performanceAdvanced R (Second Edition) Hadley Wickham. Chapters 23 24, measuring improving performanceAdvanced R (Second Edition) Hadley Wickham. Chapter 25, measuring improving performanceAdvanced R (Second Edition) Hadley Wickham. Chapter 25, measuring improving performance","code":""},{"path":"production-checklist.html","id":"production-checklist","chapter":"Checklist","heading":"Checklist","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"production-checklist.html","id":"videos-chapters-3","chapter":"Checklist","heading":"16.2 Videos / Chapters","text":"[ ][ ][ ][ ][ ][ ]","code":""},{"path":"production-checklist.html","id":"reading-3","chapter":"Checklist","heading":"16.3 Reading","text":"","code":""},{"path":"production-checklist.html","id":"activities-2","chapter":"Checklist","heading":"16.4 Activities","text":"","code":""},{"path":"production-checklist.html","id":"live-session-3","chapter":"Checklist","heading":"16.5 Live Session","text":"","code":""},{"path":"ethics-introduction.html","id":"ethics-introduction","chapter":"Introduction","heading":"Introduction","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"ethics-privacy.html","id":"ethics-privacy","chapter":"18 Privacy","heading":"18 Privacy","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"ethics-fairness.html","id":"ethics-fairness","chapter":"19 Fairness","heading":"19 Fairness","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"ethics-conduct.html","id":"ethics-conduct","chapter":"20 Fairness","heading":"20 Fairness","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"ethics-checklist.html","id":"ethics-checklist","chapter":"Checklist","heading":"Checklist","text":"Effective Data Science still work--progress. chapter currently dumping ground ideas, don’t recommend reading .like contribute development EDS, may https://github.com/zakvarty/data_science_notes.","code":""},{"path":"ethics-checklist.html","id":"videos-chapters-4","chapter":"Checklist","heading":"20.1 Videos / Chapters","text":"[ ][ ][ ][ ][ ][ ]","code":""},{"path":"ethics-checklist.html","id":"reading-4","chapter":"Checklist","heading":"20.2 Reading","text":"","code":""},{"path":"ethics-checklist.html","id":"activities-3","chapter":"Checklist","heading":"20.3 Activities","text":"","code":""},{"path":"ethics-checklist.html","id":"live-session-4","chapter":"Checklist","heading":"20.4 Live Session","text":"","code":""},{"path":"reading-list.html","id":"reading-list","chapter":"21 Reading List","heading":"21 Reading List","text":"Effective Data Science still work--progress. chapter largely complete just needs final proof reading.like contribute development EDS, may https://github.com/zakvarty/data_science_notes.reading list organised topic, according week course. split several categories.Core Materials: form core part course activities.Core Materials: form core part course activities.Reference Materials: used extensively course, seen helpful guides, rather required reading cover cover.Reference Materials: used extensively course, seen helpful guides, rather required reading cover cover.Materials Interest: form core part course, give deeper understanding interesting perspective weekly topic. might fun stuff .Materials Interest: form core part course, give deeper understanding interesting perspective weekly topic. might fun stuff .","code":""},{"path":"reading-list.html","id":"effective-data-science-workflows","chapter":"21 Reading List","heading":"21.1 Effective Data Science Workflows","text":"","code":""},{"path":"reading-list.html","id":"core-materials","chapter":"21 Reading List","heading":"Core Materials","text":"Tidyverse R Style Guide Hadley Wickham.Wilson, et al (2017). Good Enough Practices Scientific Computing. PLOS Computational Biology.","code":""},{"path":"reading-list.html","id":"reference-materials","chapter":"21 Reading List","heading":"Reference Materials","text":"R Data Science Chapters 2, 6 8 Hadley Wickham Garrett Grolemund. Chapters covering R workflow basics, scripting project based workflow.R Data Science Chapters 2, 6 8 Hadley Wickham Garrett Grolemund. Chapters covering R workflow basics, scripting project based workflow.Documentation {} packageDocumentation {} packageR Packages Book (Second Edition) Hadley Wickham Jenny Bryan.R Packages Book (Second Edition) Hadley Wickham Jenny Bryan.","code":""},{"path":"reading-list.html","id":"materials-of-interest","chapter":"21 Reading List","heading":"Materials of Interest","text":"STAT545, Part 1 Jennifer Bryan STAT 545 TAsWhat forgot teach R, Chapters 2-4 Jennifer Bryan Jim Hester.Broman et al (2017). Recommendations Funding Agencies Supporting Reproducible Research. American Statistical Association.Advanced R Hadley Wickham Section introductions functional object oriented approaches programming.Advanced R Hadley Wickham Section introductions functional object oriented approaches programming.Atlassian Article Agile Project ManagementAtlassian Article Agile Project ManagementThe Pragmatic Programmer, 20th Anniversary Edition Edition David Thomas Andrew Hunt. section DRY coding others freely available.Efficient R programming Colin Gillespie Robin Lovelace. Chapter 5 considers Efficient Input/Output relevant week. Chapter 4 Efficient Workflows links nicely last week’s topics.Efficient R programming Colin Gillespie Robin Lovelace. Chapter 5 considers Efficient Input/Output relevant week. Chapter 4 Efficient Workflows links nicely last week’s topics.Towards Principled Bayesian Workflow Michael Betancourt.Towards Principled Bayesian Workflow Michael Betancourt.Happy Git GitHub useR Jennifer Bryan","code":""},{"path":"reading-list.html","id":"aquiring-and-sharing-data","chapter":"21 Reading List","heading":"21.2 Aquiring and Sharing Data","text":"","code":""},{"path":"reading-list.html","id":"core-materials-1","chapter":"21 Reading List","heading":"Core Materials","text":"R Data Science Chapters 9 - 12 Hadley Wickham. chapters introduce tibbles data structure, import data R wrangle data tidy format.R Data Science Chapters 9 - 12 Hadley Wickham. chapters introduce tibbles data structure, import data R wrangle data tidy format.Efficient R programming Colin Gillespie Robin Lovelace. Chapter 5 considers Efficient Input/Output relevant week.Efficient R programming Colin Gillespie Robin Lovelace. Chapter 5 considers Efficient Input/Output relevant week.Wickham (2014). Tidy Data. Journal Statistical Software. paper brought tidy data mainstream.Wickham (2014). Tidy Data. Journal Statistical Software. paper brought tidy data mainstream.","code":""},{"path":"reading-list.html","id":"reference-materials-1","chapter":"21 Reading List","heading":"21.2.1 Reference Materials","text":"{readr} documentationThe {readr} documentationThe {data.table} documentation vignetteThe {data.table} documentation vignetteThe {rvest} documentationThe {rvest} documentationThe {tidyr} documentationThe {tidyr} documentationMDN Web Docs HTML CSSMDN Web Docs HTML CSS","code":""},{"path":"reading-list.html","id":"data---materials-of-interest","chapter":"21 Reading List","heading":"21.2.2 Data - Materials of Interest","text":"Introduction APIs Brian CookseyR Data Science (Second Edition) Chapters within Import section.covers importing data spreadsheets, databases, using Apache Arrow importing hierarchical data well web scraping.","code":""},{"path":"reading-list.html","id":"week-3-data-exploration-and-visualisation","chapter":"21 Reading List","heading":"21.3 Week 3: Data Exploration and Visualisation","text":"","code":""},{"path":"reading-list.html","id":"core-materials-2","chapter":"21 Reading List","heading":"21.3.1 Core Materials","text":"Exploratory Data Analysis R Roger Peng.Chapters 3 4 core reading, respectively introducing data frame manipulation {dplyr} example workflow exploratory data analysis. chapters may useful references.Flexible Imputation Missing Data Stef van Buuren. Sections 1.1-1.4 give thorough introduction missing data problems.","code":""},{"path":"reading-list.html","id":"referene-materials","chapter":"21 Reading List","heading":"Referene Materials","text":"ggplot2 Tutorial Beautiful Plotting R https://www.cedricscherer.com/2019/08/05/-ggplot2-tutorial--beautiful-plotting--r/) Cédric Scherer.ggplot2 Tutorial Beautiful Plotting R https://www.cedricscherer.com/2019/08/05/-ggplot2-tutorial--beautiful-plotting--r/) Cédric Scherer.{dplyr} documentationThe {dplyr} documentationRStudio Data Transformation Cheat SheetRStudio Data Transformation Cheat SheetR Data Science (First Edition) Chapters Data Transformations, Exploratory Data Analysis Relational Data.R Data Science (First Edition) Chapters Data Transformations, Exploratory Data Analysis Relational Data.Equivalent sections R Data Science Second EditionEquivalent sections R Data Science Second Edition","code":""},{"path":"reading-list.html","id":"materials-of-interest-1","chapter":"21 Reading List","heading":"Materials of Interest","text":"Wickham, H. (2010). Layered Grammar Graphics. Journal Computational Graphical Statistics.Wickham, H. (2010). Layered Grammar Graphics. Journal Computational Graphical Statistics.Better Data Visualisations Jonathan SchwabishBetter Data Visualisations Jonathan SchwabishData Visualization: Practical Introduction Kieran Healy","code":""},{"path":"reading-list.html","id":"preparing-for-production","chapter":"21 Reading List","heading":"21.4 Preparing for Production","text":"","code":""},{"path":"reading-list.html","id":"core-materials-3","chapter":"21 Reading List","heading":"Core Materials","text":"Ethical Algorithm M Kearns Roth (Chapter 4)Ethical Algorithm M Kearns Roth (Chapter 4)Ribeiro et al (2016). “Trust ?”: Explaining Predictions Classifier.Ribeiro et al (2016). “Trust ?”: Explaining Predictions Classifier.","code":""},{"path":"reading-list.html","id":"reference-materials-2","chapter":"21 Reading List","heading":"Reference Materials","text":"Docker Curriculum Prakhar Srivastav.Docker Curriculum Prakhar Srivastav.LIME package documentation CRAN.LIME package documentation CRAN.Interpretable Machine Learning: Guide Making Black Box Models Explainable Christoph Molnar.Interpretable Machine Learning: Guide Making Black Box Models Explainable Christoph Molnar.Documentation apply(), map() pmap()Documentation apply(), map() pmap()Advanced R (Second Edition) Hadley Wickham. Chapter 23 measuring performance Chapter 24 improving performance.Advanced R (Second Edition) Hadley Wickham. Chapter 23 measuring performance Chapter 24 improving performance.","code":""},{"path":"reading-list.html","id":"materials-of-interest-2","chapter":"21 Reading List","heading":"Materials of Interest","text":"ASA Statement \\(p\\)-values: Context, Process PurposeThe ASA Statement \\(p\\)-values: Context, Process PurposeThe Garden Forking Paths: multiple comparisons can problem,\neven “Fishing expedition” “p-hacking” research\nhypothesis posited ahead time. Gelman E loken (2013)Garden Forking Paths: multiple comparisons can problem,\neven “Fishing expedition” “p-hacking” research\nhypothesis posited ahead time. Gelman E loken (2013)Understanding LIME tutorial T Pedersen M Benesty.Understanding LIME tutorial T Pedersen M Benesty.Advanced R (Second Edition) Hadley Wickham. Chapter 25 writing R code C++.Advanced R (Second Edition) Hadley Wickham. Chapter 25 writing R code C++.","code":""},{"path":"reading-list.html","id":"data-science-ethics","chapter":"21 Reading List","heading":"21.5 Data Science Ethics","text":"","code":""},{"path":"reading-list.html","id":"core-materials-4","chapter":"21 Reading List","heading":"Core Materials","text":"Ethical Algorithm M Kearns Roth. Chapters 1 2 Algorithmic Privacy Algortihmic Fairness.Ethical Algorithm M Kearns Roth. Chapters 1 2 Algorithmic Privacy Algortihmic Fairness.Gender Shades: Intersectional Accuracy Disparities Commercial Gender Classification Joy Buolamwini Timnit Gebru (2018). Proceedings 1st Conference Fairness, Accountability Transparency.Gender Shades: Intersectional Accuracy Disparities Commercial Gender Classification Joy Buolamwini Timnit Gebru (2018). Proceedings 1st Conference Fairness, Accountability Transparency.Robust De-anonymization Large Sparse Datasets Arvind Narayanan Vitaly Shmatikov (2008). IEEE Symposium Security Privacy.Robust De-anonymization Large Sparse Datasets Arvind Narayanan Vitaly Shmatikov (2008). IEEE Symposium Security Privacy.","code":""},{"path":"reading-list.html","id":"reference-materials-3","chapter":"21 Reading List","heading":"Reference Materials","text":"Fairness machine learning\nLimitations Opportunities Solon Barocas, Moritz Hardt Arvind Narayanan.Fairness machine learning\nLimitations Opportunities Solon Barocas, Moritz Hardt Arvind Narayanan.Professional Guidleines Data Ethics :\nAmerican Mathematical Society\nEuropean Union\nUK Government\nRoyal Statistical Society\nDutch Government\nProfessional Guidleines Data Ethics :American Mathematical SocietyThe European UnionUK GovernmentRoyal Statistical SocietyDutch Government","code":""},{"path":"reading-list.html","id":"materials-of-interest-3","chapter":"21 Reading List","heading":"Materials of Interest","text":"Algorithmic Fairness (2020). Pre-print review paper Dana Pessach Erez Shmueli.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
