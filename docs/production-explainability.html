<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 13 Explainability | Effective Data Science</title>
<meta name="author" content="Zak Varty">
<meta name="description" content="Effective Data Science is still a work-in-progress. This chapter is largely complete and just needs final proof reading. If you would like to contribute to the development of EDS, you may do so at...">
<meta name="generator" content="bookdown 0.30 with bs4_book()">
<meta property="og:title" content="Chapter 13 Explainability | Effective Data Science">
<meta property="og:type" content="book">
<meta property="og:url" content="https://eds-book.zakvarty.com/production-explainability.html">
<meta property="og:image" content="https://eds-book.zakvarty.com/images/EDS-logo.jpg">
<meta property="og:description" content="Effective Data Science is still a work-in-progress. This chapter is largely complete and just needs final proof reading. If you would like to contribute to the development of EDS, you may do so at...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 13 Explainability | Effective Data Science">
<meta name="twitter:description" content="Effective Data Science is still a work-in-progress. This chapter is largely complete and just needs final proof reading. If you would like to contribute to the development of EDS, you may do so at...">
<meta name="twitter:image" content="https://eds-book.zakvarty.com/images/EDS-logo.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Effective Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">About this Course</a></li>
<li class="book-part">Effective Data Science Workflows</li>
<li><a class="" href="workflows-introduction.html">Introduction</a></li>
<li><a class="" href="workflows-organising-your-work.html"><span class="header-section-number">2</span> Organising your work</a></li>
<li><a class="" href="workflows-naming.html"><span class="header-section-number">3</span> Naming Files</a></li>
<li><a class="" href="workflows-code.html"><span class="header-section-number">4</span> Code</a></li>
<li><a class="" href="workflows-checklist.html">Checklist</a></li>
<li class="book-part">Acquiring and Sharing Data</li>
<li><a class="" href="data-introduction.html">Introduction</a></li>
<li><a class="" href="data-tabular.html"><span class="header-section-number">5</span> Tabular Data</a></li>
<li><a class="" href="data-webscraping.html"><span class="header-section-number">6</span> Web Scraping</a></li>
<li><a class="" href="data-apis.html"><span class="header-section-number">7</span> APIs</a></li>
<li><a class="" href="data-checklist.html">Checklist</a></li>
<li class="book-part">Data Exploration and Visualisation</li>
<li><a class="" href="edav-introduction.html">Introduction</a></li>
<li><a class="" href="edav-wrangling.html"><span class="header-section-number">9</span> Data Wrangling</a></li>
<li><a class="" href="edav-analysis.html"><span class="header-section-number">10</span> Exploratory Data Analysis</a></li>
<li><a class="" href="edav-visualisation.html"><span class="header-section-number">11</span> Data Visualisation</a></li>
<li><a class="" href="edav-checklist.html">Checklist</a></li>
<li class="book-part">Preparing for Production</li>
<li><a class="" href="production-introduction.html">Introduction</a></li>
<li><a class="" href="production-reproducibility.html"><span class="header-section-number">12</span> Reproducibility</a></li>
<li><a class="active" href="production-explainability.html"><span class="header-section-number">13</span> Explainability</a></li>
<li><a class="" href="production-scalability.html"><span class="header-section-number">14</span> Scalability</a></li>
<li><a class="" href="production-checklist.html">Checklist</a></li>
<li class="book-part">Data Science Ethics</li>
<li><a class="" href="ethics-introduction.html">Introduction</a></li>
<li><a class="" href="ethics-privacy.html"><span class="header-section-number">16</span> Privacy</a></li>
<li><a class="" href="ethics-fairness.html"><span class="header-section-number">17</span> Fairness</a></li>
<li><a class="" href="ethics-conduct.html"><span class="header-section-number">18</span> Codes of Conduct</a></li>
<li><a class="" href="ethics-checklist.html">Checklist</a></li>
<li><a class="" href="reading-list.html"><span class="header-section-number">19</span> Reading List</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/zakvarty/data_science_notes/">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="production-explainability" class="section level1" number="13">
<h1>
<span class="header-section-number">13</span> Explainability<a class="anchor" aria-label="anchor" href="#production-explainability"><i class="fas fa-link"></i></a>
</h1>
<div class="rmdnote">
<p>Effective Data Science is still a work-in-progress. This chapter is largely complete and just needs final proof reading.</p>
<p>If you would like to contribute to the development of EDS, you may do so at <a href="https://github.com/zakvarty/data_science_notes" class="uri">https://github.com/zakvarty/data_science_notes</a>.</p>
</div>
<div id="what-are-we-explaining-and-to-whom" class="section level2" number="13.1">
<h2>
<span class="header-section-number">13.1</span> What are we explaining and to whom?<a class="anchor" aria-label="anchor" href="#what-are-we-explaining-and-to-whom"><i class="fas fa-link"></i></a>
</h2>
<p>There are many reasons you might need to explain the behaviour of your model before it can be put into production. As an example, we can consider a credit scoring system that determines whether or not customers should be given a line of credit.</p>
<ul>
<li>Regulatory or legal requirements to describe how your model works (e.g. ban on “black-box” modelling).</li>
<li>Understanding how your model works to improve it.</li>
<li>Explaining to individual load decisions to customers.</li>
</ul>
<p>In each of these cases, what exactly do we mean by an explanation? It’s likely not the same thing in each example.</p>
<ul>
<li><p>Data scientists we might be interested to know exactly what types of mapping between covariates and responses can be represented by the neural network architecture underlying the credit scoring system.</p></li>
<li><p>Stakeholders within the company or regulators are likely indifferent to this and are more concerned about understanding the general behaviour of the model across large numbers of loan applications.</p></li>
<li><p>Finally, individual customers might have some investment in the overall behaviour of the scoring model but would also like to know what actions they can take to increase their chance of securing a loan.</p></li>
</ul>
<p>Between each of these examples, the level of technical detail differs but more importantly the fundamental nature of the explanations are different.</p>
</div>
<div id="explaining-a-decision-tree" class="section level2" number="13.2">
<h2>
<span class="header-section-number">13.2</span> Explaining a Decision Tree<a class="anchor" aria-label="anchor" href="#explaining-a-decision-tree"><i class="fas fa-link"></i></a>
</h2>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-2"></span>
<img src="images/402-production-explainability/ambulance-triage.png" alt="An example of a decision tree, optimised to correctly identify category 1 ambulance calls in as few questions as possible." width="450"><p class="caption">
Figure 10.1: An example of a decision tree, optimised to correctly identify category 1 ambulance calls in as few questions as possible.
</p>
</div>
<!--![An example of a decision tree, optimised to correctly identify category 1 ambulance calls in as pew questions as possible.](images/402-production-explainability/ambulance-triage.png){alt="Descision tree to traige ambulance calls into urgency categories.", width="80%"}-->
<p>With some models giving an explanation is relatively straightforward. Decision trees are perhaps the easiest model to explain because they mimic human decision making and can be represented like flow-charts that make sequential, linear partitions of the predictor space.</p>
<p>These models use the same sort of logic that is used for medical triage when you call an ambulance, to determine the urgency of the call. The binary decisions used in this type of triage are optimised to identify critical calls as soon as possible, but this is just one form of loss function we could use. We might instead pick these partitions to get the most accurate overall classification of calls to urgency categories. This might not be an appropriate loss function for ambulance calls but might be when deciding which loan applicants to grant credit to.</p>
<p>The issue is that these decision trees are limited in the relationships they can represent (linear relationships approximated by step function) and are sensitive to small changes in the training data. To overcome these deficiencies we can use a bootstrap aggregation or a random forest model to make predictions based on a collection of these trees. This leads to models that are more stable and flexible but also removes any chance of a simple and human-friendly explanation.</p>
</div>
<div id="explaining-regression-models" class="section level2" number="13.3">
<h2>
<span class="header-section-number">13.3</span> Explaining Regression Models<a class="anchor" aria-label="anchor" href="#explaining-regression-models"><i class="fas fa-link"></i></a>
</h2>
<p>Another model that is relatively straightforward to interpret is a linear regression. We can interpret this model using the estimated regression coefficients, which describe how the predicted outcome changes with a unit change in each covariate while the values of all other covariates are held constant.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-3"></span>
<img src="images/402-production-explainability/interpreting-linear-regression.png" alt="Linear models have global, conditional explanations, provided by the estimated regression coefficients." width="450"><p class="caption">
Figure 10.2: Linear models have global, conditional explanations, provided by the estimated regression coefficients.
</p>
</div>
<p>This is a global and a conditional explanation.</p>
<p>It is <strong>global</strong> because the effect of increasing a covariate by one unit is the same no matter what the starting value of that covariate. The explanation is the same in all parts of the covariate space.</p>
<p>The explanation is <strong>conditional</strong> because it assumes that all other values are held constant. This can lead to some odd behaviour in our explanations, they are dependent on what other terms are included (or left out of) our model.</p>
<p>This can be contrasted against non-linear regression, where covariate effects are still interpreted conditional on the value of other covariates but the size or direction of that effect might vary depending on the value of the covariate.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-4"></span>
<img src="images/402-production-explainability/interpreting-nonlinear-regression.png" alt="Non-linear models have local, conditional explanations, provided by the estimated regression coefficients." width="450"><p class="caption">
Figure 11.1: Non-linear models have local, conditional explanations, provided by the estimated regression coefficients.
</p>
</div>
<p>Here we have an example where a unit increase in the covariate is associated with a large change in the model response at low values of the covariate, but a much smaller change at large values of the covariate.</p>
</div>
<div id="example-cherrywood-regression" class="section level2" number="13.4">
<h2>
<span class="header-section-number">13.4</span> Example: Cherrywood regression<a class="anchor" aria-label="anchor" href="#example-cherrywood-regression"><i class="fas fa-link"></i></a>
</h2>
<p>As an example of this we can look at the height, girth and volume of some cherry trees.</p>
<p>If we are wanting to use a lathe to produce pretty, cherry wood ornaments we might be interested in understanding how the girth of the trees varies with their height and total volume. Using a linear model, we see that both have a positive linear association with girth.</p>
<div class="sourceCode" id="cb113"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/ggtext/">ggtext</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">lm_height</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Girth</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">Height</span>, data <span class="op">=</span> <span class="va">trees</span><span class="op">)</span></span>
<span><span class="va">lm_volume</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Girth</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">Volume</span>, data <span class="op">=</span> <span class="va">trees</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">trees</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Height</span>, y <span class="op">=</span> <span class="va">Girth</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Height"</span>, y <span class="op">=</span> <span class="st">"Girth"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">8</span>,<span class="fl">22</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Cherry Tree Dimensions"</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">trees</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">Volume</span>, y <span class="op">=</span> <span class="va">Girth</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Volume"</span>, y <span class="op">=</span> <span class="st">"Girth"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">8</span>,<span class="fl">22</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">cowplot</span><span class="fu">::</span><span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html">plot_grid</a></span><span class="op">(</span><span class="va">p1</span>, <span class="va">p2</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-5"></span>
<img src="402-production-explainability_files/figure-html/unnamed-chunk-5-1.png" alt="Cherry tree girth can be well modelled as a linear function of either tree height or harvestable volume" width="672"><p class="caption">
Figure 10.3: Cherry tree girth can be well modelled as a linear function of either tree height or harvestable volume
</p>
</div>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Girth</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">Height</span>, data <span class="op">=</span> <span class="va">trees</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = Girth ~ 1 + Height, data = trees)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt; (Intercept)       Height  </span></span>
<span><span class="co">#&gt;     -6.1884       0.2557</span></span></code></pre></div>
<div class="sourceCode" id="cb115"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Girth</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">Volume</span>, data <span class="op">=</span> <span class="va">trees</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = Girth ~ 1 + Volume, data = trees)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt; (Intercept)       Volume  </span></span>
<span><span class="co">#&gt;      7.6779       0.1846</span></span></code></pre></div>
<p>However, when we include both terms in our model, our interpretation changes dramatically.</p>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Girth</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">Height</span> <span class="op">+</span> <span class="va">Volume</span>, data <span class="op">=</span> <span class="va">trees</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = Girth ~ 1 + Height + Volume, data = trees)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt; (Intercept)       Height       Volume  </span></span>
<span><span class="co">#&gt;    10.81637     -0.04548      0.19518</span></span></code></pre></div>
<p>Height is no longer positively associated with girth. This is because the size, direction and significance of our estimated effects is conditional on what other terms are included in the model. For a <em>fixed volume</em> of wood, a taller tree necessarily has to have a smaller girth.</p>
<p>Techniques such as <a href="https://christophm.github.io/interpretable-ml-book/shap.html">SHAP</a> try to quantify the importance of a predictor by averaging over all combinations of predictors that might be included within the model. You can read more about such techniques in <a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a> by Christoph Molnar.</p>
</div>
<div id="simpsons-paradox" class="section level2" number="13.5">
<h2>
<span class="header-section-number">13.5</span> Simpson’s Paradox<a class="anchor" aria-label="anchor" href="#simpsons-paradox"><i class="fas fa-link"></i></a>
</h2>
<p>This effect is related to <strong>Simpson’s Paradox</strong>, where a trend appears in several groups of data but disappears or reverses when the groups are combined.</p>
<p>This regularly arises in fields like epidemiology, where population level trends are assumed to apply at the level of individuals or small groups, where this is known as the ecological fallacy.</p>
<p>Actually, Simpson’s parodox is a terrible name, because it isn’t actually a paradox at all. It’s not surprising that we have two different answers to two different questions, the supposed contradiction only arises when we fail to distinguish between those questions.</p>
<div class="sourceCode" id="cb117"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data_1</span> <span class="op">&lt;-</span> <span class="fu">mgcv</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/mgcv/man/rmvn.html">rmvn</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span>, mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">4</span><span class="op">)</span>, V <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">0.8</span>,<span class="fl">0.8</span>,<span class="fl">2</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data_2</span> <span class="op">&lt;-</span> <span class="fu">mgcv</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/mgcv/man/rmvn.html">rmvn</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span>, mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>, V <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">0.8</span>,<span class="fl">0.8</span>,<span class="fl">2</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">data_3</span> <span class="op">&lt;-</span> <span class="fu">mgcv</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/mgcv/man/rmvn.html">rmvn</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">100</span>, mu <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>,<span class="fl">0</span><span class="op">)</span>, V <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">0.8</span>,<span class="fl">0.8</span>,<span class="fl">2</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">simpson</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  x_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">data_1</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>, <span class="va">data_2</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>, <span class="va">data_3</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span><span class="op">)</span>, </span>
<span>  x_2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">data_1</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, <span class="va">data_2</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span>, <span class="va">data_3</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  group <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, each <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">p3</span> <span class="op">&lt;-</span> <span class="va">simpson</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_1</span>, y <span class="op">=</span> <span class="va">x_2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">"Simpson's Paradox"</span>, <span class="st">"Groupings Unknown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">p4</span> <span class="op">&lt;-</span> <span class="va">simpson</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_by.html">group_by</a></span><span class="op">(</span><span class="va">group</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x_1</span>, y <span class="op">=</span> <span class="va">x_2</span>, col <span class="op">=</span> <span class="va">group</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span><span class="op">(</span><span class="st">""</span>, <span class="st">"Groupings Unknown"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">cowplot</span><span class="fu">::</span><span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html">plot_grid</a></span><span class="op">(</span><span class="va">p3</span>, <span class="va">p4</span>, ncol <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; `geom_smooth()` using formula = 'y ~ x'</span></span>
<span><span class="co">#&gt; `geom_smooth()` using formula = 'y ~ x'</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-9"></span>
<img src="402-production-explainability_files/figure-html/unnamed-chunk-9-1.png" alt="A simulated example in which a covariate has a negative trend at the population level but a positive trend within each sub-group." width="672"><p class="caption">
Figure 13.1: A simulated example in which a covariate has a negative trend at the population level but a positive trend within each sub-group.
</p>
</div>
<p>What I hope to have highlighted here is that for some of the simplest models we might use as data scietists, explanations are very much possible but must be made with care and attention to detail - correctly interpreting these models in context can be far from straightforward.</p>
</div>
<div id="what-hope-do-we-have" class="section level2" number="13.6">
<h2>
<span class="header-section-number">13.6</span> What hope do we have?<a class="anchor" aria-label="anchor" href="#what-hope-do-we-have"><i class="fas fa-link"></i></a>
</h2>
<p>At this stage, you might be asking yourself what hope we have of explaining more complex models like random forests or neural networks, given how difficuly it is to explain even the simple models we might take as our benchmark. You’d be right to worry about this and it is important to remain humble in what we can and cannot know about these complex systems that we are building.</p>
<p>All hope isn’t lost though - we still have a few tricks up our sleeve!</p>
<div id="permutation-testing" class="section level3" number="13.6.1">
<h3>
<span class="header-section-number">13.6.1</span> Permutation Testing<a class="anchor" aria-label="anchor" href="#permutation-testing"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose we’re asked by our product manager to determine which predictors or covariates are usually the most import in our model when determining credit scores and loan outcomes.</p>
<p>One way to do this would be to remove each covariate from the model and investigate how that changes the predictions made by our model. However, we’ve seen already that removing a predictor can substantively change some models.</p>
<p>So instead, we could answer this question by using permutation methods.</p>
<p>If we take the observed values of a covariate, say income, and randomly allocate these among all our training examples then this will destroy any association between income and loan outcome. This allows us to remove the information provided by income but without altering the overall structure of our model. We can then refit our model to this modified data set and investigate how rearranging the covariate alters our predictions. If there is a large performance drop, then the covariate is playing an important role within our model.</p>
<p>There are many variations on this sort of permutation test. They can be simple but powerful tools for understanding the behaviour of all sorts of model.</p>
</div>
<div id="meta-modelling" class="section level3" number="13.6.2">
<h3>
<span class="header-section-number">13.6.2</span> Meta-modelling<a class="anchor" aria-label="anchor" href="#meta-modelling"><i class="fas fa-link"></i></a>
</h3>
<p>Meta-models are, as the name suggests, models of models and these can be effective methods of providing localised explanations for complex models.</p>
<p>The idea here is to look at a small region of the covariate space that is covered by a complex and highly flexible model, such as a neural network. We can’t easily give a global explanation for this complex model’s behaviour - it is just too complicated.</p>
<p>However, we can interrogate the model’s behaviour within a small region and construct a simplified version of the model (a meta-model) that lets us explain the model within that small region. Often this meta-model is chosen as a linear model.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="images/402-production-explainability/local-linear-approximation.png" alt="A local linear approximation in two dimensions" width="450"><p class="caption">
Figure 13.2: A local linear approximation in two dimensions
</p>
</div>
<p>This is partly for convenience and familiarity but also has a theoretical backing: if our complex model is sufficiently smooth then we can appeal to <a href="https://en.wikipedia.org/wiki/Taylor%27s_theorem">Taylor’s Theorem</a> to say that in a small enough region the mapping can be well approximated by a linear function.</p>
<p>This sort of local model explanation is particularly useful where we want to explain individual predictions or decisions made by our model: for example why a single loan applicant was not granted a loan. By inspecting the coefficients of this local surrogate model we can identify which covariates were the most influential in the decision and suggest how the applicant could increase their chance of success by summarising those covariates that were both influential and are within the ability of the applicant to change. This is exactly the approach taken by the <a href="https://christophm.github.io/interpretable-ml-book/lime.html">LIME</a> methodology developed by Ribiero et al. </p>
</div>
<div id="aggregating-meta-models" class="section level3" number="13.6.3">
<h3>
<span class="header-section-number">13.6.3</span> Aggregating Meta-models<a class="anchor" aria-label="anchor" href="#aggregating-meta-models"><i class="fas fa-link"></i></a>
</h3>
<p>Using local or conditional explanations of our model’s behaviour can be useful in some circumstances but they don’t give a broader understanding of what is going on overall. What if we want to know how a covariate influences <em>all</em> outcomes not a particular one? What if we care about the covariate’s expected effect over all loan applicants, or the <em>distribution</em> of effects over all applicants?</p>
<p>This is where local and conditional explanations are particularly nice. By making these explanations at many points we can aggregate these explanations to understand the global and marginal behaviour of our models.</p>
<p>To aggregate our conditional effects into a marginal effect, or a local effect into a global effect we must integrate these over the joint distribution of all covariates. If this sounds a bit scary to you, then you are right. Integration is hard enough at the best of times without adding in the fact that we don’t know the joint distribution of the covariates we are using as predictors.</p>
<p>Don’t worry though, we can take the easy way out and do both of these things approximately. We can approximate the joint distribution of the covariates by the empirical distribution that we observe in our sample, and then our nasty integrals simplify to averages over the measurement units in our data (the loan applicants in our case).</p>
<p>If we construct a local, conditional model for each loan applicant in our data set, we can approximate the marginal effect of each covariate by averaging the conditional effects we obtain for each loan applicant.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-11"></span>
<img src="images/402-production-explainability/local-neighbourhoods.png" alt="Local approximations around each observation can be combined to understand global model behaviour." width="450"><p class="caption">
Figure 13.3: Local approximations around each observation can be combined to understand global model behaviour.
</p>
</div>
<p>This gives us a global understanding of how each covariate influences the response of our model. It does this over all possible values of the other covariates and appropriately weights these according to their frequency within the sample (and also within the population, if our sample is representative).</p>
</div>
</div>
<div id="wrapping-up-6" class="section level2" number="13.7">
<h2>
<span class="header-section-number">13.7</span> Wrapping Up<a class="anchor" aria-label="anchor" href="#wrapping-up-6"><i class="fas fa-link"></i></a>
</h2>
<p>We’ve seen that as our models become more flexible they also become more difficult to explain, whether that is to ourselves, and subject expert or a user of our model.</p>
<p>That’s not to say that simple models are always easy to explain or interpret, simple models can be deceptively tricky to communicate accurately.</p>
<p>Finally, we looked at a couple of techniques for explaining more complex models.</p>
<p>We can use permutation tests measure feature importance in our models: shuffling the predictor values breaks any relationship to our response, and we can measure how much this degrades our model performance. A big dip implies that feature was doing a lot of explaining.</p>
<p>We can also look at the local behaviour of models by making surrogate or meta models, that are interpretable, and aggregate these to understand the model globally.</p>
<p>Effective explanations are essential if you want your model to be used in production and to feed into real decisions decision making. This requires some level of skill with rhetoric to tailor your explanation so that it is clear to the person who requested it. But this isn’t a soft skill, it also requires a surprising amount of computational and mathematical skill to extract such explanations from complex modern models.
<!-- 

* LIME paper on ArXiV: https://arxiv.org/abs/1602.04938. Ribeiro et al (2016) "Why Should I Trust You?": Explaining the Predictions of Any Classifier.


* LIME pacakge documentation on CRAN https://cran.r-project.org/web/packages/lime/index.html  

* Understanding LIME tutorial -  T Pedersen and M Benesty 

https://cran.r-project.org/web/packages/lime/vignettes/Understanding_lime.html 

* Reference: Interpretable Machine Learning: A Guide for Making Black Box Models Explainable by Christoph Molnar 
--></p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="production-reproducibility.html"><span class="header-section-number">12</span> Reproducibility</a></div>
<div class="next"><a href="production-scalability.html"><span class="header-section-number">14</span> Scalability</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#production-explainability"><span class="header-section-number">13</span> Explainability</a></li>
<li><a class="nav-link" href="#what-are-we-explaining-and-to-whom"><span class="header-section-number">13.1</span> What are we explaining and to whom?</a></li>
<li><a class="nav-link" href="#explaining-a-decision-tree"><span class="header-section-number">13.2</span> Explaining a Decision Tree</a></li>
<li><a class="nav-link" href="#explaining-regression-models"><span class="header-section-number">13.3</span> Explaining Regression Models</a></li>
<li><a class="nav-link" href="#example-cherrywood-regression"><span class="header-section-number">13.4</span> Example: Cherrywood regression</a></li>
<li><a class="nav-link" href="#simpsons-paradox"><span class="header-section-number">13.5</span> Simpson’s Paradox</a></li>
<li>
<a class="nav-link" href="#what-hope-do-we-have"><span class="header-section-number">13.6</span> What hope do we have?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#permutation-testing"><span class="header-section-number">13.6.1</span> Permutation Testing</a></li>
<li><a class="nav-link" href="#meta-modelling"><span class="header-section-number">13.6.2</span> Meta-modelling</a></li>
<li><a class="nav-link" href="#aggregating-meta-models"><span class="header-section-number">13.6.3</span> Aggregating Meta-models</a></li>
</ul>
</li>
<li><a class="nav-link" href="#wrapping-up-6"><span class="header-section-number">13.7</span> Wrapping Up</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/zakvarty/data_science_notes//blob/master/402-production-explainability.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/zakvarty/data_science_notes//edit/master/402-production-explainability.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Effective Data Science</strong>" was written by Zak Varty. It was last built on 2023-02-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
